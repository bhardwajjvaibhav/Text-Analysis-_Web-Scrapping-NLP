{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3924a973-1cc2-4702-96f7-ab9d3ccfa052",
   "metadata": {},
   "source": [
    "## Text Anlaysis Flow\n",
    "##### 1. Data Extraction using Beautiful scoop and creating seperate text file for each url (containing only article heading and content)\n",
    "#####    each text file be named as the name of its url_id and stored in a directory \"aritcles\"\n",
    "##### 2. From given master dictionary containing positive and negative words for text analysis and stopwords . Creating sets for each of them    #####  #####    seperately \n",
    "##### 3. Text analysis is divided into two modules:\n",
    "#####    a. Analysis pre-stopwords removal \n",
    "#####    b. Analysis post-stopwords          Reason for dividing the text analysis into two divison was:\n",
    "#####                                        1. Some metrics needed to be calculated pre stop words removal\n",
    "#####                                        2. For ease of functions\n",
    "##### 4. First part calculate :::    1. POSITIVE_SCORE  2.NEGATIVE_SCORE  3.Syllable_Count   4.num_words  5.Polartiy_Score  6.Subjectivity_Score  \n",
    "##### 5. Second part calculate :::   1.avg_sentence_length  2.percentage_complex_words 3.fog  4.Average_Number_of_Words_Per_Sentence  \n",
    "#####                                5.complex_word_count 6. Average_word_length  7.num_personal_pronouns  \n",
    "##### 6. Merging the two data frames and updating the Output data file.                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97a6f675-eb47-484b-a512-19ad44f7c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import nltk\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165ca219-438c-450b-b822-63a981fae9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SK\n",
      "[nltk_data]     SHARMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\SK\n",
      "[nltk_data]     SHARMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to C:\\Users\\SK\n",
      "[nltk_data]     SHARMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt')\n",
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66984685-235c-43e6-ad6a-23efcde31165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...\n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file = 'input.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d4f88-a2e5-438d-a4d7-defcfc551027",
   "metadata": {},
   "source": [
    "### Data Extraction from the URLS using Beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed8d2a8-6898-4061-a8eb-4acafddb2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'URL_ID' not in df.columns or 'URL' not in df.columns:\n",
    "    raise ValueError(\"Excel file must contain 'url_id' and 'url' columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2601b621-0f0c-465d-bea5-b5097b662334",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('articles', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ae2816-a013-4949-bd4a-b584b6b77e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed blackassign0001: https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/\n",
      "Processed blackassign0002: https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/\n",
      "Processed blackassign0003: https://insights.blackcoffer.com/internet-demands-evolution-communication-impact-and-2035s-alternative-pathways/\n",
      "Processed blackassign0004: https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-in-upcoming-future/\n",
      "Processed blackassign0005: https://insights.blackcoffer.com/ott-platform-and-its-impact-on-the-entertainment-industry-in-future/\n",
      "Processed blackassign0006: https://insights.blackcoffer.com/the-rise-of-the-ott-platform-and-its-impact-on-the-entertainment-industry-by-2040/\n",
      "Processed blackassign0007: https://insights.blackcoffer.com/rise-of-cyber-crime-and-its-effects/\n",
      "Processed blackassign0008: https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035-2/\n",
      "Processed blackassign0009: https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040-2/\n",
      "Processed blackassign0010: https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040/\n",
      "Processed blackassign0011: https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035/\n",
      "Processed blackassign0012: https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/\n",
      "Processed blackassign0013: https://insights.blackcoffer.com/rise-of-e-health-and-its-impact-on-humans-by-the-year-2030/\n",
      "Processed blackassign0014: https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/\n",
      "Processed blackassign0015: https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2/\n",
      "Processed blackassign0016: https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2-2/\n",
      "Processed blackassign0017: https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/\n",
      "Processed blackassign0018: https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030/\n",
      "Processed blackassign0019: https://insights.blackcoffer.com/how-does-marketing-influence-businesses-and-consumers/\n",
      "Processed blackassign0020: https://insights.blackcoffer.com/how-advertisement-increase-your-market-value/\n",
      "Processed blackassign0021: https://insights.blackcoffer.com/negative-effects-of-marketing-on-society/\n",
      "Processed blackassign0022: https://insights.blackcoffer.com/how-advertisement-marketing-affects-business/\n",
      "Processed blackassign0023: https://insights.blackcoffer.com/rising-it-cities-will-impact-the-economy-environment-infrastructure-and-city-life-by-the-year-2035/\n",
      "Processed blackassign0024: https://insights.blackcoffer.com/rise-of-ott-platform-and-its-impact-on-entertainment-industry-by-the-year-2030/\n",
      "Processed blackassign0025: https://insights.blackcoffer.com/rise-of-electric-vehicles-and-its-impact-on-livelihood-by-2040/\n",
      "Processed blackassign0026: https://insights.blackcoffer.com/rise-of-electric-vehicle-and-its-impact-on-livelihood-by-the-year-2040/\n",
      "Processed blackassign0027: https://insights.blackcoffer.com/oil-prices-by-the-year-2040-and-how-it-will-impact-the-world-economy/\n",
      "Processed blackassign0028: https://insights.blackcoffer.com/an-outlook-of-healthcare-by-the-year-2040-and-how-it-will-impact-human-lives/\n",
      "Processed blackassign0029: https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\n",
      "Processed blackassign0030: https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\n",
      "Processed blackassign0031: https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\n",
      "Processed blackassign0032: https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\n",
      "Processed blackassign0033: https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\n",
      "Processed blackassign0034: https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\n",
      "Processed blackassign0035: https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\n",
      "Error fetching https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "Processed blackassign0036: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "Processed blackassign0037: https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\n",
      "Processed blackassign0038: https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\n",
      "Processed blackassign0039: https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/\n",
      "Processed blackassign0040: https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/\n",
      "Processed blackassign0041: https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/\n",
      "Processed blackassign0042: https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/\n",
      "Processed blackassign0043: https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/\n",
      "Processed blackassign0044: https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\n",
      "Processed blackassign0045: https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/\n",
      "Processed blackassign0046: https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/\n",
      "Processed blackassign0047: https://insights.blackcoffer.com/evolution-of-advertising-industry/\n",
      "Processed blackassign0048: https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/\n",
      "Error fetching https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "Processed blackassign0049: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "Processed blackassign0050: https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/\n",
      "Processed blackassign0051: https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/\n",
      "Processed blackassign0052: https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/\n",
      "Processed blackassign0053: https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/\n",
      "Processed blackassign0054: https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\n",
      "Processed blackassign0055: https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/\n",
      "Processed blackassign0056: https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/\n",
      "Processed blackassign0057: https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/\n",
      "Processed blackassign0058: https://insights.blackcoffer.com/how-we-forecast-future-technologies/\n",
      "Processed blackassign0059: https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\n",
      "Processed blackassign0060: https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/\n",
      "Processed blackassign0061: https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/\n",
      "Processed blackassign0062: https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/\n",
      "Processed blackassign0063: https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/\n",
      "Processed blackassign0064: https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\n",
      "Processed blackassign0065: https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/\n",
      "Processed blackassign0066: https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/\n",
      "Processed blackassign0067: https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/\n",
      "Processed blackassign0068: https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/\n",
      "Processed blackassign0069: https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/\n",
      "Processed blackassign0070: https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/\n",
      "Processed blackassign0071: https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\n",
      "Processed blackassign0072: https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/\n",
      "Processed blackassign0073: https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/\n",
      "Processed blackassign0074: https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/\n",
      "Processed blackassign0075: https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/\n",
      "Processed blackassign0076: https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/\n",
      "Processed blackassign0077: https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/\n",
      "Processed blackassign0078: https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/\n",
      "Processed blackassign0079: https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/\n",
      "Processed blackassign0080: https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/\n",
      "Processed blackassign0081: https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/\n",
      "Processed blackassign0082: https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/\n",
      "Processed blackassign0083: https://insights.blackcoffer.com/human-rights-outlook/\n",
      "Processed blackassign0084: https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\n",
      "Processed blackassign0085: https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/\n",
      "Processed blackassign0086: https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/\n",
      "Processed blackassign0087: https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/\n",
      "Processed blackassign0088: https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/\n",
      "Processed blackassign0089: https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/\n",
      "Processed blackassign0090: https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/\n",
      "Processed blackassign0091: https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/\n",
      "Processed blackassign0092: https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/\n",
      "Processed blackassign0093: https://insights.blackcoffer.com/travel-and-tourism-outlook/\n",
      "Processed blackassign0094: https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/\n",
      "Processed blackassign0095: https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/\n",
      "Processed blackassign0096: https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/\n",
      "Processed blackassign0097: https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/\n",
      "Processed blackassign0098: https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/\n",
      "Processed blackassign0099: https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/\n",
      "Processed blackassign0100: https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/\n",
      "Finished fetching articles.\n"
     ]
    }
   ],
   "source": [
    "def fetch_article(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Assuming the title is in a <title> or <h1> tag\n",
    "        title = soup.find('title') or soup.find('h1')\n",
    "        if title:\n",
    "            title = title.get_text(strip=True)\n",
    "        else:\n",
    "            title = \"No Title Found\"\n",
    "\n",
    "        content_div = soup.find('div', class_='article-content') or soup.find('article')\n",
    "        if content_div:\n",
    "            paragraphs = content_div.find_all('p')\n",
    "            content = '\\n'.join([para.get_text(strip=True) for para in paragraphs])\n",
    "        else:\n",
    "            content = \"No Content Found\"\n",
    "\n",
    "        return title, content\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    title, content = fetch_article(url)\n",
    "    if title and content:\n",
    "      \n",
    "        file_name = f'articles/{url_id}.txt'\n",
    "        with open(file_name, 'w', encoding='utf-8') as file:\n",
    "            file.write(f\"Title: {title}\\n\\n{content}\")\n",
    "\n",
    "    print(f\"Processed {url_id}: {url}\")\n",
    "\n",
    "print(\"Finished fetching articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc715f-c760-4699-9eca-0c01141eb88c",
   "metadata": {},
   "source": [
    "### Creating given Stopwords set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910b59f4-34bd-4d89-9004-0d7b2d953713",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set()\n",
    "for files in os.listdir('F:\\JUPYTER NOTEBOOK\\StopWords'):\n",
    "  with open(os.path.join('F:\\JUPYTER NOTEBOOK\\StopWords',files),'r',encoding='ISO-8859-1') as f:\n",
    "    stop_words.update(set(f.read().splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf02ecc-4f60-4670-b805-3f16c612e669",
   "metadata": {},
   "source": [
    "### Creating given Positive and Negative Word sets for the text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ce766e-6c1d-4c58-aa2c-f24a60c4a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = set()\n",
    "negative_words=set()\n",
    "with open('psw.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        positive_words.add(line.strip())\n",
    "with open('neg.txt','r',encoding='ISO-8859-1') as f:\n",
    "    for line in f :\n",
    "        negative_words.add(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3db10-8547-4871-a12e-0929a922f8fa",
   "metadata": {},
   "source": [
    "### Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b826b865-65f1-488e-8fad-682b1bf539bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 URL_ID  POSITIVE_SCORE  NEGATIVE_SCORE  Syllable_Count  \\\n",
      "0   blackassign0001.txt               6               1             299   \n",
      "1   blackassign0002.txt              56              29            1501   \n",
      "2   blackassign0003.txt              38              24            1414   \n",
      "3   blackassign0004.txt              38              75            1282   \n",
      "4   blackassign0005.txt              21               8             707   \n",
      "..                  ...             ...             ...             ...   \n",
      "93  blackassign0096.txt              29              57            1090   \n",
      "94  blackassign0097.txt              25              35             740   \n",
      "95  blackassign0098.txt               1               0             188   \n",
      "96  blackassign0099.txt              16               3             416   \n",
      "97  blackassign0100.txt              31              55             801   \n",
      "\n",
      "    num_words  Polartiy_Score  Subjectivity_Score  \n",
      "0         175        0.714286            0.014493  \n",
      "1         788        0.317647            0.175983  \n",
      "2         637        0.225806            0.128364  \n",
      "3         617       -0.327434            0.233954  \n",
      "4         376        0.448276            0.060041  \n",
      "..        ...             ...                 ...  \n",
      "93        587       -0.325581            0.178054  \n",
      "94        451       -0.166667            0.124224  \n",
      "95         95        0.999999            0.002070  \n",
      "96        276        0.684210            0.039337  \n",
      "97        483       -0.279070            0.178054  \n",
      "\n",
      "[98 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(text, positive_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    countp = sum(1 for token in tokens if token.lower() in positive_words)\n",
    "    return countp\n",
    "\n",
    "def count_negative_words(text, negative_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    count = sum(-1 for token in tokens if token.lower() in negative_words) * -1\n",
    "    return count\n",
    "\n",
    "def count_syllables(text):\n",
    "    \"\"\"Count syllables in a word using the CMU Pronouncing Dictionary.\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    total_syllables = 0\n",
    "    for word in words:\n",
    "        if word.lower() in prondict:\n",
    "            \n",
    "            syllables = [len(list(y for y in x if y[-1].isdigit())) for x in prondict[word.lower()] if not (word.endswith('es') or word.endswith('ed'))]\n",
    "            total_syllables += max(syllables) if syllables else 0\n",
    "    return total_syllables\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_and_count_words(text):\n",
    "   \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    cleaned_words = [word for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "\n",
    "    num_words = len(cleaned_words)\n",
    "    \n",
    "  \n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    \n",
    "    return cleaned_text, num_words\n",
    "\n",
    "\n",
    "def main():\n",
    "    articles_dir = 'articles'\n",
    "    results=[]\n",
    "    error_files = []\n",
    "  \n",
    "    for text_file in os.listdir(articles_dir):\n",
    "        positive_word_count = 0  # Reset positive word count\n",
    "        negative_word_count = 0  # Reset negative word count\n",
    "        \n",
    "        file_path = os.path.join(articles_dir, text_file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        url_id = text_file\n",
    "        positive_word_count = count_positive_words(text, positive_words)\n",
    "        negative_word_count = count_negative_words(text, negative_words)\n",
    "        syllable_count = count_syllables(text)  \n",
    "        cleaned_text, num_words = clean_and_count_words(text)\n",
    "        \n",
    "        results.append({\n",
    "            'URL_ID': url_id,\n",
    "            'POSITIVE_SCORE': positive_word_count,\n",
    "            'NEGATIVE_SCORE': negative_word_count,\n",
    "            'Syllable_Count': syllable_count,\n",
    "            'num_words':num_words\n",
    "        })\n",
    " \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    results_df['Polartiy_Score']= (results_df['POSITIVE_SCORE'] - results_df['NEGATIVE_SCORE'])/ ((results_df['POSITIVE_SCORE']+results_df['NEGATIVE_SCORE']) + 0.000001)\n",
    "    results_df['Subjectivity_Score']=(results_df['POSITIVE_SCORE'] + results_df['NEGATIVE_SCORE'])/(num_words +0.000001)\n",
    "    print(results_df)\n",
    "    return results_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    results_df=main()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8535b3-5b2c-4d6d-adae-7a2f5b7dd903",
   "metadata": {},
   "source": [
    "#### Removing Stopwords and updating each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3dec285-0e84-4413-98e3-e5cac94d6203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed blackassign0001.txt\n",
      "Processed blackassign0002.txt\n",
      "Processed blackassign0003.txt\n",
      "Processed blackassign0004.txt\n",
      "Processed blackassign0005.txt\n",
      "Processed blackassign0006.txt\n",
      "Processed blackassign0007.txt\n",
      "Processed blackassign0008.txt\n",
      "Processed blackassign0009.txt\n",
      "Processed blackassign0010.txt\n",
      "Processed blackassign0011.txt\n",
      "Processed blackassign0012.txt\n",
      "Processed blackassign0013.txt\n",
      "Processed blackassign0014.txt\n",
      "Processed blackassign0015.txt\n",
      "Processed blackassign0016.txt\n",
      "Processed blackassign0017.txt\n",
      "Processed blackassign0018.txt\n",
      "Processed blackassign0019.txt\n",
      "Processed blackassign0020.txt\n",
      "Processed blackassign0021.txt\n",
      "Processed blackassign0022.txt\n",
      "Processed blackassign0023.txt\n",
      "Processed blackassign0024.txt\n",
      "Processed blackassign0025.txt\n",
      "Processed blackassign0026.txt\n",
      "Processed blackassign0027.txt\n",
      "Processed blackassign0028.txt\n",
      "Processed blackassign0029.txt\n",
      "Processed blackassign0030.txt\n",
      "Processed blackassign0031.txt\n",
      "Processed blackassign0032.txt\n",
      "Processed blackassign0033.txt\n",
      "Processed blackassign0034.txt\n",
      "Processed blackassign0035.txt\n",
      "Processed blackassign0037.txt\n",
      "Processed blackassign0038.txt\n",
      "Processed blackassign0039.txt\n",
      "Processed blackassign0040.txt\n",
      "Processed blackassign0041.txt\n",
      "Processed blackassign0042.txt\n",
      "Processed blackassign0043.txt\n",
      "Processed blackassign0044.txt\n",
      "Processed blackassign0045.txt\n",
      "Processed blackassign0046.txt\n",
      "Processed blackassign0047.txt\n",
      "Processed blackassign0048.txt\n",
      "Processed blackassign0050.txt\n",
      "Processed blackassign0051.txt\n",
      "Processed blackassign0052.txt\n",
      "Processed blackassign0053.txt\n",
      "Processed blackassign0054.txt\n",
      "Processed blackassign0055.txt\n",
      "Processed blackassign0056.txt\n",
      "Processed blackassign0057.txt\n",
      "Processed blackassign0058.txt\n",
      "Processed blackassign0059.txt\n",
      "Processed blackassign0060.txt\n",
      "Processed blackassign0061.txt\n",
      "Processed blackassign0062.txt\n",
      "Processed blackassign0063.txt\n",
      "Processed blackassign0064.txt\n",
      "Processed blackassign0065.txt\n",
      "Processed blackassign0066.txt\n",
      "Processed blackassign0067.txt\n",
      "Processed blackassign0068.txt\n",
      "Processed blackassign0069.txt\n",
      "Processed blackassign0070.txt\n",
      "Processed blackassign0071.txt\n",
      "Processed blackassign0072.txt\n",
      "Processed blackassign0073.txt\n",
      "Processed blackassign0074.txt\n",
      "Processed blackassign0075.txt\n",
      "Processed blackassign0076.txt\n",
      "Processed blackassign0077.txt\n",
      "Processed blackassign0078.txt\n",
      "Processed blackassign0079.txt\n",
      "Processed blackassign0080.txt\n",
      "Processed blackassign0081.txt\n",
      "Processed blackassign0082.txt\n",
      "Processed blackassign0083.txt\n",
      "Processed blackassign0084.txt\n",
      "Processed blackassign0085.txt\n",
      "Processed blackassign0086.txt\n",
      "Processed blackassign0087.txt\n",
      "Processed blackassign0088.txt\n",
      "Processed blackassign0089.txt\n",
      "Processed blackassign0090.txt\n",
      "Processed blackassign0091.txt\n",
      "Processed blackassign0092.txt\n",
      "Processed blackassign0093.txt\n",
      "Processed blackassign0094.txt\n",
      "Processed blackassign0095.txt\n",
      "Processed blackassign0096.txt\n",
      "Processed blackassign0097.txt\n",
      "Processed blackassign0098.txt\n",
      "Processed blackassign0099.txt\n",
      "Processed blackassign0100.txt\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    return ' '.join(word for word in text.split() if word.lower() not in stopwords)\n",
    "def main():\n",
    "    articles_dir = 'articles'\n",
    "    for text_file in os.listdir(articles_dir):\n",
    "        file_path = os.path.join(articles_dir, text_file)\n",
    "        if os.path.isfile(file_path) and text_file.endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            cleaned_text = remove_stopwords(text, stop_words)\n",
    "            \n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(cleaned_text)\n",
    "            \n",
    "            print(f\"Processed {text_file}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8219f64-c573-4d2f-bb0c-1589f2b7fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed blackassign0001.txt: {'avg_sentence_length': 8.72, 'percentage_complex_words': 44.4954128440367, 'fog': 21.28616513761468, 'Average_Number_of_Words_Per_Sentence': 8.72, 'complex_word_count': 97, 'Average_word_length': 5.385321100917431, 'num_personal_pronouns': 0, 'filename': 'blackassign0001.txt'}\n",
      "Processed blackassign0002.txt: {'avg_sentence_length': 13.2, 'percentage_complex_words': 47.878787878787875, 'fog': 24.431515151515153, 'Average_Number_of_Words_Per_Sentence': 13.2, 'complex_word_count': 474, 'Average_word_length': 6.097979797979798, 'num_personal_pronouns': 2, 'filename': 'blackassign0002.txt'}\n",
      "Processed blackassign0003.txt: {'avg_sentence_length': 14.089285714285714, 'percentage_complex_words': 56.27376425855514, 'fog': 28.145219989136343, 'Average_Number_of_Words_Per_Sentence': 14.089285714285714, 'complex_word_count': 444, 'Average_word_length': 6.845373891001268, 'num_personal_pronouns': 1, 'filename': 'blackassign0003.txt'}\n",
      "Processed blackassign0004.txt: {'avg_sentence_length': 15.48, 'percentage_complex_words': 52.97157622739018, 'fog': 27.380630490956072, 'Average_Number_of_Words_Per_Sentence': 15.48, 'complex_word_count': 410, 'Average_word_length': 6.607235142118863, 'num_personal_pronouns': 0, 'filename': 'blackassign0004.txt'}\n",
      "Processed blackassign0005.txt: {'avg_sentence_length': 11.717948717948717, 'percentage_complex_words': 50.32822757111597, 'fog': 24.818470515625876, 'Average_Number_of_Words_Per_Sentence': 11.717948717948717, 'complex_word_count': 230, 'Average_word_length': 6.356673960612691, 'num_personal_pronouns': 0, 'filename': 'blackassign0005.txt'}\n",
      "Processed blackassign0006.txt: {'avg_sentence_length': 16.987179487179485, 'percentage_complex_words': 53.81132075471699, 'fog': 28.319400096758592, 'Average_Number_of_Words_Per_Sentence': 16.987179487179485, 'complex_word_count': 713, 'Average_word_length': 6.77811320754717, 'num_personal_pronouns': 1, 'filename': 'blackassign0006.txt'}\n",
      "Processed blackassign0007.txt: {'avg_sentence_length': 10.559322033898304, 'percentage_complex_words': 46.869983948635635, 'fog': 22.97172239301358, 'Average_Number_of_Words_Per_Sentence': 10.559322033898304, 'complex_word_count': 292, 'Average_word_length': 5.930979133226324, 'num_personal_pronouns': 0, 'filename': 'blackassign0007.txt'}\n",
      "Processed blackassign0008.txt: {'avg_sentence_length': 12.97872340425532, 'percentage_complex_words': 52.459016393442624, 'fog': 26.17509591907918, 'Average_Number_of_Words_Per_Sentence': 12.97872340425532, 'complex_word_count': 320, 'Average_word_length': 6.745901639344262, 'num_personal_pronouns': 0, 'filename': 'blackassign0008.txt'}\n",
      "Processed blackassign0009.txt: {'avg_sentence_length': 13.192982456140351, 'percentage_complex_words': 51.329787234042556, 'fog': 25.809107876073167, 'Average_Number_of_Words_Per_Sentence': 13.192982456140351, 'complex_word_count': 386, 'Average_word_length': 6.672872340425532, 'num_personal_pronouns': 0, 'filename': 'blackassign0009.txt'}\n",
      "Processed blackassign0010.txt: {'avg_sentence_length': 12.173333333333334, 'percentage_complex_words': 45.2354874041621, 'fog': 22.963528294998174, 'Average_Number_of_Words_Per_Sentence': 12.173333333333334, 'complex_word_count': 413, 'Average_word_length': 6.615553121577218, 'num_personal_pronouns': 5, 'filename': 'blackassign0010.txt'}\n",
      "Processed blackassign0011.txt: {'avg_sentence_length': 14.738461538461538, 'percentage_complex_words': 57.09812108559499, 'fog': 28.734633049622616, 'Average_Number_of_Words_Per_Sentence': 14.738461538461538, 'complex_word_count': 547, 'Average_word_length': 6.6680584551148225, 'num_personal_pronouns': 1, 'filename': 'blackassign0011.txt'}\n",
      "Processed blackassign0012.txt: {'avg_sentence_length': 13.278481012658228, 'percentage_complex_words': 60.81982840800762, 'fog': 29.639323768266344, 'Average_Number_of_Words_Per_Sentence': 13.278481012658228, 'complex_word_count': 638, 'Average_word_length': 6.637750238322211, 'num_personal_pronouns': 2, 'filename': 'blackassign0012.txt'}\n",
      "Processed blackassign0013.txt: {'avg_sentence_length': 14.166666666666666, 'percentage_complex_words': 57.35294117647059, 'fog': 28.607843137254903, 'Average_Number_of_Words_Per_Sentence': 14.166666666666666, 'complex_word_count': 195, 'Average_word_length': 7.023529411764706, 'num_personal_pronouns': 1, 'filename': 'blackassign0013.txt'}\n",
      "Processed blackassign0014.txt: {'avg_sentence_length': 10.26865671641791, 'percentage_complex_words': 46.94767441860465, 'fog': 22.886532454009025, 'Average_Number_of_Words_Per_Sentence': 10.26865671641791, 'complex_word_count': 323, 'Average_word_length': 6.094476744186046, 'num_personal_pronouns': 0, 'filename': 'blackassign0014.txt'}\n",
      "Processed blackassign0015.txt: {'avg_sentence_length': 13.913793103448276, 'percentage_complex_words': 50.55762081784386, 'fog': 25.78856556851686, 'Average_Number_of_Words_Per_Sentence': 13.913793103448276, 'complex_word_count': 408, 'Average_word_length': 6.315985130111524, 'num_personal_pronouns': 1, 'filename': 'blackassign0015.txt'}\n",
      "Processed blackassign0016.txt: {'avg_sentence_length': 13.913793103448276, 'percentage_complex_words': 50.55762081784386, 'fog': 25.78856556851686, 'Average_Number_of_Words_Per_Sentence': 13.913793103448276, 'complex_word_count': 408, 'Average_word_length': 6.315985130111524, 'num_personal_pronouns': 1, 'filename': 'blackassign0016.txt'}\n",
      "Processed blackassign0017.txt: {'avg_sentence_length': 12.338983050847459, 'percentage_complex_words': 50.137362637362635, 'fog': 24.990538275284038, 'Average_Number_of_Words_Per_Sentence': 12.338983050847459, 'complex_word_count': 365, 'Average_word_length': 6.184065934065934, 'num_personal_pronouns': 0, 'filename': 'blackassign0017.txt'}\n",
      "Processed blackassign0018.txt: {'avg_sentence_length': 16.795454545454547, 'percentage_complex_words': 48.3085250338295, 'fog': 26.041591831713617, 'Average_Number_of_Words_Per_Sentence': 16.795454545454547, 'complex_word_count': 357, 'Average_word_length': 6.200270635994587, 'num_personal_pronouns': 0, 'filename': 'blackassign0018.txt'}\n",
      "Processed blackassign0019.txt: {'avg_sentence_length': 11.378947368421052, 'percentage_complex_words': 51.988899167437566, 'fog': 25.34713861434345, 'Average_Number_of_Words_Per_Sentence': 11.378947368421052, 'complex_word_count': 562, 'Average_word_length': 6.123959296947271, 'num_personal_pronouns': 12, 'filename': 'blackassign0019.txt'}\n",
      "Processed blackassign0020.txt: {'avg_sentence_length': 11.076923076923077, 'percentage_complex_words': 54.861111111111114, 'fog': 26.37521367521368, 'Average_Number_of_Words_Per_Sentence': 11.076923076923077, 'complex_word_count': 158, 'Average_word_length': 5.684027777777778, 'num_personal_pronouns': 2, 'filename': 'blackassign0020.txt'}\n",
      "Processed blackassign0021.txt: {'avg_sentence_length': 14.081632653061224, 'percentage_complex_words': 54.927536231884055, 'fog': 27.603667553978113, 'Average_Number_of_Words_Per_Sentence': 14.081632653061224, 'complex_word_count': 379, 'Average_word_length': 6.1869565217391305, 'num_personal_pronouns': 3, 'filename': 'blackassign0021.txt'}\n",
      "Processed blackassign0022.txt: {'avg_sentence_length': 8.74074074074074, 'percentage_complex_words': 49.57627118644068, 'fog': 23.32680477087257, 'Average_Number_of_Words_Per_Sentence': 8.74074074074074, 'complex_word_count': 117, 'Average_word_length': 5.970338983050848, 'num_personal_pronouns': 1, 'filename': 'blackassign0022.txt'}\n",
      "Processed blackassign0023.txt: {'avg_sentence_length': 13.672131147540984, 'percentage_complex_words': 50.59952038369304, 'fog': 25.708660612493613, 'Average_Number_of_Words_Per_Sentence': 13.672131147540984, 'complex_word_count': 422, 'Average_word_length': 5.934052757793765, 'num_personal_pronouns': 4, 'filename': 'blackassign0023.txt'}\n",
      "Processed blackassign0024.txt: {'avg_sentence_length': 19.94736842105263, 'percentage_complex_words': 48.02110817941953, 'fog': 27.187390640188866, 'Average_Number_of_Words_Per_Sentence': 19.94736842105263, 'complex_word_count': 182, 'Average_word_length': 5.8654353562005275, 'num_personal_pronouns': 0, 'filename': 'blackassign0024.txt'}\n",
      "Processed blackassign0025.txt: {'avg_sentence_length': 28.652173913043477, 'percentage_complex_words': 40.36418816388468, 'fog': 27.60654483077126, 'Average_Number_of_Words_Per_Sentence': 28.652173913043477, 'complex_word_count': 266, 'Average_word_length': 5.300455235204856, 'num_personal_pronouns': 3, 'filename': 'blackassign0025.txt'}\n",
      "Processed blackassign0026.txt: {'avg_sentence_length': 15.317073170731707, 'percentage_complex_words': 46.01910828025478, 'fog': 24.534472580394596, 'Average_Number_of_Words_Per_Sentence': 15.317073170731707, 'complex_word_count': 289, 'Average_word_length': 5.671974522292993, 'num_personal_pronouns': 1, 'filename': 'blackassign0026.txt'}\n",
      "Processed blackassign0027.txt: {'avg_sentence_length': 15.26530612244898, 'percentage_complex_words': 37.29946524064171, 'fog': 21.025908545236277, 'Average_Number_of_Words_Per_Sentence': 15.26530612244898, 'complex_word_count': 279, 'Average_word_length': 5.510695187165775, 'num_personal_pronouns': 4, 'filename': 'blackassign0027.txt'}\n",
      "Processed blackassign0028.txt: {'avg_sentence_length': 19.64864864864865, 'percentage_complex_words': 46.49243466299862, 'fog': 26.456433324658907, 'Average_Number_of_Words_Per_Sentence': 19.64864864864865, 'complex_word_count': 338, 'Average_word_length': 6.066024759284732, 'num_personal_pronouns': 1, 'filename': 'blackassign0028.txt'}\n",
      "Processed blackassign0029.txt: {'avg_sentence_length': 16.786666666666665, 'percentage_complex_words': 55.04368546465449, 'fog': 28.73214085252846, 'Average_Number_of_Words_Per_Sentence': 16.786666666666665, 'complex_word_count': 693, 'Average_word_length': 6.328038125496426, 'num_personal_pronouns': 3, 'filename': 'blackassign0029.txt'}\n",
      "Processed blackassign0030.txt: {'avg_sentence_length': 11.30379746835443, 'percentage_complex_words': 38.96976483762598, 'fog': 20.109424922392165, 'Average_Number_of_Words_Per_Sentence': 11.30379746835443, 'complex_word_count': 348, 'Average_word_length': 5.191489361702128, 'num_personal_pronouns': 18, 'filename': 'blackassign0030.txt'}\n",
      "Processed blackassign0031.txt: {'avg_sentence_length': 13.023529411764706, 'percentage_complex_words': 53.20686540198736, 'fog': 26.49215792550083, 'Average_Number_of_Words_Per_Sentence': 13.023529411764706, 'complex_word_count': 589, 'Average_word_length': 6.1924119241192415, 'num_personal_pronouns': 6, 'filename': 'blackassign0031.txt'}\n",
      "Processed blackassign0032.txt: {'avg_sentence_length': 9.902173913043478, 'percentage_complex_words': 50.82327113062569, 'fog': 24.290178017467667, 'Average_Number_of_Words_Per_Sentence': 9.902173913043478, 'complex_word_count': 463, 'Average_word_length': 5.54774972557629, 'num_personal_pronouns': 2, 'filename': 'blackassign0032.txt'}\n",
      "Processed blackassign0033.txt: {'avg_sentence_length': 14.142857142857142, 'percentage_complex_words': 46.92378328741965, 'fog': 24.426656172110718, 'Average_Number_of_Words_Per_Sentence': 14.142857142857142, 'complex_word_count': 511, 'Average_word_length': 5.675849403122131, 'num_personal_pronouns': 9, 'filename': 'blackassign0033.txt'}\n",
      "Processed blackassign0034.txt: {'avg_sentence_length': 13.982142857142858, 'percentage_complex_words': 43.93358876117497, 'fog': 23.16629264732713, 'Average_Number_of_Words_Per_Sentence': 13.982142857142858, 'complex_word_count': 344, 'Average_word_length': 5.472541507024266, 'num_personal_pronouns': 12, 'filename': 'blackassign0034.txt'}\n",
      "Processed blackassign0035.txt: {'avg_sentence_length': 10.6, 'percentage_complex_words': 44.0251572327044, 'fog': 21.850062893081763, 'Average_Number_of_Words_Per_Sentence': 10.6, 'complex_word_count': 210, 'Average_word_length': 5.620545073375262, 'num_personal_pronouns': 1, 'filename': 'blackassign0035.txt'}\n",
      "Processed blackassign0037.txt: {'avg_sentence_length': 12.685714285714285, 'percentage_complex_words': 44.14414414414414, 'fog': 22.731943371943373, 'Average_Number_of_Words_Per_Sentence': 12.685714285714285, 'complex_word_count': 196, 'Average_word_length': 5.376126126126126, 'num_personal_pronouns': 7, 'filename': 'blackassign0037.txt'}\n",
      "Processed blackassign0038.txt: {'avg_sentence_length': 16.02469135802469, 'percentage_complex_words': 49.922958397534664, 'fog': 26.379059902223744, 'Average_Number_of_Words_Per_Sentence': 16.02469135802469, 'complex_word_count': 648, 'Average_word_length': 5.659476117103236, 'num_personal_pronouns': 8, 'filename': 'blackassign0038.txt'}\n",
      "Processed blackassign0039.txt: {'avg_sentence_length': 15.175824175824175, 'percentage_complex_words': 40.55032585083273, 'fog': 22.290460010662763, 'Average_Number_of_Words_Per_Sentence': 15.175824175824175, 'complex_word_count': 560, 'Average_word_length': 5.141202027516292, 'num_personal_pronouns': 28, 'filename': 'blackassign0039.txt'}\n",
      "Processed blackassign0040.txt: {'avg_sentence_length': 12.862068965517242, 'percentage_complex_words': 56.70241286863271, 'fog': 27.825792733659984, 'Average_Number_of_Words_Per_Sentence': 12.862068965517242, 'complex_word_count': 423, 'Average_word_length': 6.438337801608579, 'num_personal_pronouns': 4, 'filename': 'blackassign0040.txt'}\n",
      "Processed blackassign0041.txt: {'avg_sentence_length': 10.794871794871796, 'percentage_complex_words': 44.418052256532064, 'fog': 22.085169620561544, 'Average_Number_of_Words_Per_Sentence': 10.794871794871796, 'complex_word_count': 374, 'Average_word_length': 5.353919239904988, 'num_personal_pronouns': 3, 'filename': 'blackassign0041.txt'}\n",
      "Processed blackassign0042.txt: {'avg_sentence_length': 13.918032786885245, 'percentage_complex_words': 50.05889281507656, 'fog': 25.590770240784725, 'Average_Number_of_Words_Per_Sentence': 13.918032786885245, 'complex_word_count': 425, 'Average_word_length': 5.99057714958775, 'num_personal_pronouns': 10, 'filename': 'blackassign0042.txt'}\n",
      "Processed blackassign0043.txt: {'avg_sentence_length': 13.064102564102564, 'percentage_complex_words': 47.20314033366046, 'fog': 24.10689715910521, 'Average_Number_of_Words_Per_Sentence': 13.064102564102564, 'complex_word_count': 481, 'Average_word_length': 5.558390578999019, 'num_personal_pronouns': 6, 'filename': 'blackassign0043.txt'}\n",
      "Processed blackassign0044.txt: {'avg_sentence_length': 15.227272727272727, 'percentage_complex_words': 55.82089552238806, 'fog': 28.419267299864316, 'Average_Number_of_Words_Per_Sentence': 15.227272727272727, 'complex_word_count': 187, 'Average_word_length': 6.3194029850746265, 'num_personal_pronouns': 1, 'filename': 'blackassign0044.txt'}\n",
      "Processed blackassign0045.txt: {'avg_sentence_length': 95.55555555555556, 'percentage_complex_words': 53.604651162790695, 'fog': 59.6640826873385, 'Average_Number_of_Words_Per_Sentence': 95.55555555555556, 'complex_word_count': 461, 'Average_word_length': 6.241860465116279, 'num_personal_pronouns': 12, 'filename': 'blackassign0045.txt'}\n",
      "Processed blackassign0046.txt: {'avg_sentence_length': 10.666666666666666, 'percentage_complex_words': 51.24999999999999, 'fog': 24.766666666666666, 'Average_Number_of_Words_Per_Sentence': 10.666666666666666, 'complex_word_count': 246, 'Average_word_length': 5.78125, 'num_personal_pronouns': 3, 'filename': 'blackassign0046.txt'}\n",
      "Processed blackassign0047.txt: {'avg_sentence_length': 12.0, 'percentage_complex_words': 51.66666666666667, 'fog': 25.46666666666667, 'Average_Number_of_Words_Per_Sentence': 12.0, 'complex_word_count': 248, 'Average_word_length': 6.241666666666666, 'num_personal_pronouns': 3, 'filename': 'blackassign0047.txt'}\n",
      "Processed blackassign0048.txt: {'avg_sentence_length': 16.428571428571427, 'percentage_complex_words': 44.34782608695652, 'fog': 24.31055900621118, 'Average_Number_of_Words_Per_Sentence': 16.428571428571427, 'complex_word_count': 51, 'Average_word_length': 5.843478260869565, 'num_personal_pronouns': 0, 'filename': 'blackassign0048.txt'}\n",
      "Processed blackassign0050.txt: {'avg_sentence_length': 15.618181818181819, 'percentage_complex_words': 44.70314318975553, 'fog': 24.12853000317494, 'Average_Number_of_Words_Per_Sentence': 15.618181818181819, 'complex_word_count': 384, 'Average_word_length': 5.90803259604191, 'num_personal_pronouns': 1, 'filename': 'blackassign0050.txt'}\n",
      "Processed blackassign0051.txt: {'avg_sentence_length': 15.206896551724139, 'percentage_complex_words': 48.29931972789115, 'fog': 25.402486511846117, 'Average_Number_of_Words_Per_Sentence': 15.206896551724139, 'complex_word_count': 213, 'Average_word_length': 5.712018140589569, 'num_personal_pronouns': 2, 'filename': 'blackassign0051.txt'}\n",
      "Processed blackassign0052.txt: {'avg_sentence_length': 9.944954128440367, 'percentage_complex_words': 48.247232472324725, 'fog': 23.276874640306037, 'Average_Number_of_Words_Per_Sentence': 9.944954128440367, 'complex_word_count': 523, 'Average_word_length': 5.615313653136531, 'num_personal_pronouns': 8, 'filename': 'blackassign0052.txt'}\n",
      "Processed blackassign0053.txt: {'avg_sentence_length': 11.25, 'percentage_complex_words': 49.629629629629626, 'fog': 24.35185185185185, 'Average_Number_of_Words_Per_Sentence': 11.25, 'complex_word_count': 201, 'Average_word_length': 6.012345679012346, 'num_personal_pronouns': 2, 'filename': 'blackassign0053.txt'}\n",
      "Processed blackassign0054.txt: {'avg_sentence_length': 15.733333333333333, 'percentage_complex_words': 38.559322033898304, 'fog': 21.71706214689266, 'Average_Number_of_Words_Per_Sentence': 15.733333333333333, 'complex_word_count': 91, 'Average_word_length': 5.728813559322034, 'num_personal_pronouns': 1, 'filename': 'blackassign0054.txt'}\n",
      "Processed blackassign0055.txt: {'avg_sentence_length': 15.029411764705882, 'percentage_complex_words': 41.878669275929546, 'fog': 22.763232416254173, 'Average_Number_of_Words_Per_Sentence': 15.029411764705882, 'complex_word_count': 214, 'Average_word_length': 5.295499021526418, 'num_personal_pronouns': 1, 'filename': 'blackassign0055.txt'}\n",
      "Processed blackassign0056.txt: {'avg_sentence_length': 17.526315789473685, 'percentage_complex_words': 53.453453453453456, 'fog': 28.39190769717086, 'Average_Number_of_Words_Per_Sentence': 17.526315789473685, 'complex_word_count': 178, 'Average_word_length': 5.876876876876877, 'num_personal_pronouns': 2, 'filename': 'blackassign0056.txt'}\n",
      "Processed blackassign0057.txt: {'avg_sentence_length': 8.346153846153847, 'percentage_complex_words': 52.995391705069125, 'fog': 24.53661822048919, 'Average_Number_of_Words_Per_Sentence': 8.346153846153847, 'complex_word_count': 115, 'Average_word_length': 6.142857142857143, 'num_personal_pronouns': 0, 'filename': 'blackassign0057.txt'}\n",
      "Processed blackassign0058.txt: {'avg_sentence_length': 11.555555555555555, 'percentage_complex_words': 52.88461538461539, 'fog': 25.77606837606838, 'Average_Number_of_Words_Per_Sentence': 11.555555555555555, 'complex_word_count': 55, 'Average_word_length': 6.653846153846154, 'num_personal_pronouns': 0, 'filename': 'blackassign0058.txt'}\n",
      "Processed blackassign0059.txt: {'avg_sentence_length': 9.4, 'percentage_complex_words': 42.359767891682786, 'fog': 20.703907156673115, 'Average_Number_of_Words_Per_Sentence': 9.4, 'complex_word_count': 219, 'Average_word_length': 4.947775628626692, 'num_personal_pronouns': 8, 'filename': 'blackassign0059.txt'}\n",
      "Processed blackassign0060.txt: {'avg_sentence_length': 12.11111111111111, 'percentage_complex_words': 45.87155963302752, 'fog': 23.193068297655454, 'Average_Number_of_Words_Per_Sentence': 12.11111111111111, 'complex_word_count': 50, 'Average_word_length': 5.5504587155963305, 'num_personal_pronouns': 0, 'filename': 'blackassign0060.txt'}\n",
      "Processed blackassign0061.txt: {'avg_sentence_length': 15.233333333333333, 'percentage_complex_words': 53.39168490153173, 'fog': 27.45000729394603, 'Average_Number_of_Words_Per_Sentence': 15.233333333333333, 'complex_word_count': 244, 'Average_word_length': 6.424507658643326, 'num_personal_pronouns': 2, 'filename': 'blackassign0061.txt'}\n",
      "Processed blackassign0062.txt: {'avg_sentence_length': 14.5, 'percentage_complex_words': 36.7816091954023, 'fog': 20.51264367816092, 'Average_Number_of_Words_Per_Sentence': 14.5, 'complex_word_count': 32, 'Average_word_length': 5.540229885057471, 'num_personal_pronouns': 1, 'filename': 'blackassign0062.txt'}\n",
      "Processed blackassign0063.txt: {'avg_sentence_length': 8.681818181818182, 'percentage_complex_words': 48.167539267015705, 'fog': 22.739742979533556, 'Average_Number_of_Words_Per_Sentence': 8.681818181818182, 'complex_word_count': 92, 'Average_word_length': 5.727748691099476, 'num_personal_pronouns': 7, 'filename': 'blackassign0063.txt'}\n",
      "Processed blackassign0064.txt: {'avg_sentence_length': 15.445945945945946, 'percentage_complex_words': 49.08136482939632, 'fog': 25.81092431013691, 'Average_Number_of_Words_Per_Sentence': 15.445945945945946, 'complex_word_count': 561, 'Average_word_length': 6.036745406824147, 'num_personal_pronouns': 3, 'filename': 'blackassign0064.txt'}\n",
      "Processed blackassign0065.txt: {'avg_sentence_length': 13.865671641791044, 'percentage_complex_words': 44.241119483315394, 'fog': 23.24271645004258, 'Average_Number_of_Words_Per_Sentence': 13.865671641791044, 'complex_word_count': 411, 'Average_word_length': 5.66200215285253, 'num_personal_pronouns': 1, 'filename': 'blackassign0065.txt'}\n",
      "Processed blackassign0066.txt: {'avg_sentence_length': 11.654320987654321, 'percentage_complex_words': 39.51271186440678, 'fog': 20.466813140824442, 'Average_Number_of_Words_Per_Sentence': 11.654320987654321, 'complex_word_count': 373, 'Average_word_length': 5.301906779661017, 'num_personal_pronouns': 5, 'filename': 'blackassign0066.txt'}\n",
      "Processed blackassign0067.txt: {'avg_sentence_length': 7.590163934426229, 'percentage_complex_words': 41.46868250539957, 'fog': 19.623538575930322, 'Average_Number_of_Words_Per_Sentence': 7.590163934426229, 'complex_word_count': 192, 'Average_word_length': 5.304535637149028, 'num_personal_pronouns': 4, 'filename': 'blackassign0067.txt'}\n",
      "Processed blackassign0068.txt: {'avg_sentence_length': 11.796875, 'percentage_complex_words': 42.91390728476821, 'fog': 21.884312913907284, 'Average_Number_of_Words_Per_Sentence': 11.796875, 'complex_word_count': 324, 'Average_word_length': 5.215894039735099, 'num_personal_pronouns': 5, 'filename': 'blackassign0068.txt'}\n",
      "Processed blackassign0069.txt: {'avg_sentence_length': 15.875, 'percentage_complex_words': 46.8503937007874, 'fog': 25.09015748031496, 'Average_Number_of_Words_Per_Sentence': 15.875, 'complex_word_count': 119, 'Average_word_length': 5.480314960629921, 'num_personal_pronouns': 4, 'filename': 'blackassign0069.txt'}\n",
      "Processed blackassign0070.txt: {'avg_sentence_length': 15.144927536231885, 'percentage_complex_words': 50.717703349282296, 'fog': 26.345052354205674, 'Average_Number_of_Words_Per_Sentence': 15.144927536231885, 'complex_word_count': 530, 'Average_word_length': 5.837320574162679, 'num_personal_pronouns': 4, 'filename': 'blackassign0070.txt'}\n",
      "Processed blackassign0071.txt: {'avg_sentence_length': 8.0, 'percentage_complex_words': 38.15789473684211, 'fog': 18.463157894736845, 'Average_Number_of_Words_Per_Sentence': 8.0, 'complex_word_count': 232, 'Average_word_length': 5.095394736842105, 'num_personal_pronouns': 13, 'filename': 'blackassign0071.txt'}\n",
      "Processed blackassign0072.txt: {'avg_sentence_length': 8.759493670886076, 'percentage_complex_words': 36.41618497109826, 'fog': 18.070271456793733, 'Average_Number_of_Words_Per_Sentence': 8.759493670886076, 'complex_word_count': 252, 'Average_word_length': 5.160404624277457, 'num_personal_pronouns': 7, 'filename': 'blackassign0072.txt'}\n",
      "Processed blackassign0073.txt: {'avg_sentence_length': 14.906976744186046, 'percentage_complex_words': 39.15756630265211, 'fog': 21.625817218735264, 'Average_Number_of_Words_Per_Sentence': 14.906976744186046, 'complex_word_count': 251, 'Average_word_length': 5.380655226209049, 'num_personal_pronouns': 0, 'filename': 'blackassign0073.txt'}\n",
      "Processed blackassign0074.txt: {'avg_sentence_length': 11.95, 'percentage_complex_words': 48.04469273743017, 'fog': 23.99787709497207, 'Average_Number_of_Words_Per_Sentence': 11.933333333333334, 'complex_word_count': 344, 'Average_word_length': 5.819832402234637, 'num_personal_pronouns': 1, 'filename': 'blackassign0074.txt'}\n",
      "Processed blackassign0075.txt: {'avg_sentence_length': 8.534246575342467, 'percentage_complex_words': 39.325842696629216, 'fog': 19.144035708788675, 'Average_Number_of_Words_Per_Sentence': 8.534246575342467, 'complex_word_count': 245, 'Average_word_length': 5.15569823434992, 'num_personal_pronouns': 14, 'filename': 'blackassign0075.txt'}\n",
      "Processed blackassign0076.txt: {'avg_sentence_length': 14.10344827586207, 'percentage_complex_words': 41.80929095354523, 'fog': 22.36509569176292, 'Average_Number_of_Words_Per_Sentence': 14.10344827586207, 'complex_word_count': 171, 'Average_word_length': 5.579462102689487, 'num_personal_pronouns': 2, 'filename': 'blackassign0076.txt'}\n",
      "Processed blackassign0077.txt: {'avg_sentence_length': 16.363636363636363, 'percentage_complex_words': 50.55555555555556, 'fog': 26.767676767676768, 'Average_Number_of_Words_Per_Sentence': 16.363636363636363, 'complex_word_count': 91, 'Average_word_length': 5.677777777777778, 'num_personal_pronouns': 0, 'filename': 'blackassign0077.txt'}\n",
      "Processed blackassign0078.txt: {'avg_sentence_length': 20.434782608695652, 'percentage_complex_words': 51.70212765957447, 'fog': 28.854764107308053, 'Average_Number_of_Words_Per_Sentence': 20.434782608695652, 'complex_word_count': 243, 'Average_word_length': 6.193617021276595, 'num_personal_pronouns': 1, 'filename': 'blackassign0078.txt'}\n",
      "Processed blackassign0079.txt: {'avg_sentence_length': 13.964285714285714, 'percentage_complex_words': 38.74680306905371, 'fog': 21.084435513335773, 'Average_Number_of_Words_Per_Sentence': 13.964285714285714, 'complex_word_count': 303, 'Average_word_length': 5.7774936061381075, 'num_personal_pronouns': 1, 'filename': 'blackassign0079.txt'}\n",
      "Processed blackassign0080.txt: {'avg_sentence_length': 14.202072538860104, 'percentage_complex_words': 33.81977380518059, 'fog': 19.20873853761628, 'Average_Number_of_Words_Per_Sentence': 14.202072538860104, 'complex_word_count': 927, 'Average_word_length': 4.944545786209413, 'num_personal_pronouns': 0, 'filename': 'blackassign0080.txt'}\n",
      "Processed blackassign0081.txt: {'avg_sentence_length': 12.353658536585366, 'percentage_complex_words': 48.07502467917078, 'fog': 24.171473286302458, 'Average_Number_of_Words_Per_Sentence': 12.353658536585366, 'complex_word_count': 487, 'Average_word_length': 5.91609081934847, 'num_personal_pronouns': 11, 'filename': 'blackassign0081.txt'}\n",
      "Processed blackassign0082.txt: {'avg_sentence_length': 17.016949152542374, 'percentage_complex_words': 52.589641434262944, 'fog': 27.842636234722125, 'Average_Number_of_Words_Per_Sentence': 17.016949152542374, 'complex_word_count': 528, 'Average_word_length': 6.075697211155378, 'num_personal_pronouns': 1, 'filename': 'blackassign0082.txt'}\n",
      "Processed blackassign0083.txt: {'avg_sentence_length': 12.571428571428571, 'percentage_complex_words': 38.63636363636363, 'fog': 20.48311688311688, 'Average_Number_of_Words_Per_Sentence': 12.571428571428571, 'complex_word_count': 34, 'Average_word_length': 5.215909090909091, 'num_personal_pronouns': 1, 'filename': 'blackassign0083.txt'}\n",
      "Processed blackassign0084.txt: {'avg_sentence_length': 14.973684210526315, 'percentage_complex_words': 38.13708260105449, 'fog': 21.244306724632324, 'Average_Number_of_Words_Per_Sentence': 14.973684210526315, 'complex_word_count': 217, 'Average_word_length': 5.014059753954306, 'num_personal_pronouns': 6, 'filename': 'blackassign0084.txt'}\n",
      "Processed blackassign0085.txt: {'avg_sentence_length': 7.991666666666666, 'percentage_complex_words': 42.33576642335766, 'fog': 20.130973236009734, 'Average_Number_of_Words_Per_Sentence': 7.991666666666666, 'complex_word_count': 406, 'Average_word_length': 5.819603753910323, 'num_personal_pronouns': 6, 'filename': 'blackassign0085.txt'}\n",
      "Processed blackassign0086.txt: {'avg_sentence_length': 12.055555555555555, 'percentage_complex_words': 42.94930875576037, 'fog': 22.001945724526372, 'Average_Number_of_Words_Per_Sentence': 12.055555555555555, 'complex_word_count': 466, 'Average_word_length': 5.447004608294931, 'num_personal_pronouns': 15, 'filename': 'blackassign0086.txt'}\n",
      "Processed blackassign0087.txt: {'avg_sentence_length': 14.652173913043478, 'percentage_complex_words': 43.17507418397626, 'fog': 23.130899238807896, 'Average_Number_of_Words_Per_Sentence': 14.652173913043478, 'complex_word_count': 291, 'Average_word_length': 5.670623145400594, 'num_personal_pronouns': 7, 'filename': 'blackassign0087.txt'}\n",
      "Processed blackassign0088.txt: {'avg_sentence_length': 19.87719298245614, 'percentage_complex_words': 48.89673433362754, 'fog': 27.509570926433476, 'Average_Number_of_Words_Per_Sentence': 19.87719298245614, 'complex_word_count': 554, 'Average_word_length': 6.041482789055604, 'num_personal_pronouns': 0, 'filename': 'blackassign0088.txt'}\n",
      "Processed blackassign0089.txt: {'avg_sentence_length': 12.97872340425532, 'percentage_complex_words': 46.39344262295082, 'fog': 23.748866410882457, 'Average_Number_of_Words_Per_Sentence': 12.97872340425532, 'complex_word_count': 283, 'Average_word_length': 5.801639344262295, 'num_personal_pronouns': 0, 'filename': 'blackassign0089.txt'}\n",
      "Processed blackassign0090.txt: {'avg_sentence_length': 9.472222222222221, 'percentage_complex_words': 46.774193548387096, 'fog': 22.498566308243728, 'Average_Number_of_Words_Per_Sentence': 9.472222222222221, 'complex_word_count': 319, 'Average_word_length': 5.737536656891495, 'num_personal_pronouns': 2, 'filename': 'blackassign0090.txt'}\n",
      "Processed blackassign0091.txt: {'avg_sentence_length': 15.944444444444445, 'percentage_complex_words': 52.961672473867594, 'fog': 27.562446767324815, 'Average_Number_of_Words_Per_Sentence': 15.944444444444445, 'complex_word_count': 304, 'Average_word_length': 6.301393728222997, 'num_personal_pronouns': 3, 'filename': 'blackassign0091.txt'}\n",
      "Processed blackassign0092.txt: {'avg_sentence_length': 16.2, 'percentage_complex_words': 39.73063973063973, 'fog': 22.372255892255893, 'Average_Number_of_Words_Per_Sentence': 16.2, 'complex_word_count': 354, 'Average_word_length': 5.610549943883277, 'num_personal_pronouns': 2, 'filename': 'blackassign0092.txt'}\n",
      "Processed blackassign0093.txt: {'avg_sentence_length': 12.222222222222221, 'percentage_complex_words': 40.0, 'fog': 20.88888888888889, 'Average_Number_of_Words_Per_Sentence': 12.222222222222221, 'complex_word_count': 44, 'Average_word_length': 5.245454545454545, 'num_personal_pronouns': 1, 'filename': 'blackassign0093.txt'}\n",
      "Processed blackassign0094.txt: {'avg_sentence_length': 11.285714285714286, 'percentage_complex_words': 40.50632911392405, 'fog': 20.716817359855337, 'Average_Number_of_Words_Per_Sentence': 11.285714285714286, 'complex_word_count': 288, 'Average_word_length': 5.490857946554149, 'num_personal_pronouns': 4, 'filename': 'blackassign0094.txt'}\n",
      "Processed blackassign0095.txt: {'avg_sentence_length': 12.771428571428572, 'percentage_complex_words': 34.899328859060404, 'fog': 19.068302972195593, 'Average_Number_of_Words_Per_Sentence': 12.771428571428572, 'complex_word_count': 156, 'Average_word_length': 5.43847874720358, 'num_personal_pronouns': 2, 'filename': 'blackassign0095.txt'}\n",
      "Processed blackassign0096.txt: {'avg_sentence_length': 14.145833333333334, 'percentage_complex_words': 53.31369661266569, 'fog': 26.98381197839961, 'Average_Number_of_Words_Per_Sentence': 14.145833333333334, 'complex_word_count': 362, 'Average_word_length': 6.438880706921944, 'num_personal_pronouns': 1, 'filename': 'blackassign0096.txt'}\n",
      "Processed blackassign0097.txt: {'avg_sentence_length': 15.447368421052632, 'percentage_complex_words': 38.841567291311755, 'fog': 21.715574284945756, 'Average_Number_of_Words_Per_Sentence': 15.447368421052632, 'complex_word_count': 228, 'Average_word_length': 5.3816013628620105, 'num_personal_pronouns': 1, 'filename': 'blackassign0097.txt'}\n",
      "Processed blackassign0098.txt: {'avg_sentence_length': 24.6, 'percentage_complex_words': 47.96747967479675, 'fog': 29.0269918699187, 'Average_Number_of_Words_Per_Sentence': 24.6, 'complex_word_count': 59, 'Average_word_length': 5.471544715447155, 'num_personal_pronouns': 0, 'filename': 'blackassign0098.txt'}\n",
      "Processed blackassign0099.txt: {'avg_sentence_length': 12.214285714285714, 'percentage_complex_words': 43.567251461988306, 'fog': 22.31261487050961, 'Average_Number_of_Words_Per_Sentence': 12.214285714285714, 'complex_word_count': 149, 'Average_word_length': 5.286549707602339, 'num_personal_pronouns': 2, 'filename': 'blackassign0099.txt'}\n",
      "Processed blackassign0100.txt: {'avg_sentence_length': 18.806451612903224, 'percentage_complex_words': 45.1114922813036, 'fog': 25.56717755768273, 'Average_Number_of_Words_Per_Sentence': 18.806451612903224, 'complex_word_count': 263, 'Average_word_length': 5.981132075471698, 'num_personal_pronouns': 2, 'filename': 'blackassign0100.txt'}\n",
      "    avg_sentence_length  percentage_complex_words        fog  \\\n",
      "0              8.720000                 44.495413  21.286165   \n",
      "1             13.200000                 47.878788  24.431515   \n",
      "2             14.089286                 56.273764  28.145220   \n",
      "3             15.480000                 52.971576  27.380630   \n",
      "4             11.717949                 50.328228  24.818471   \n",
      "..                  ...                       ...        ...   \n",
      "93            14.145833                 53.313697  26.983812   \n",
      "94            15.447368                 38.841567  21.715574   \n",
      "95            24.600000                 47.967480  29.026992   \n",
      "96            12.214286                 43.567251  22.312615   \n",
      "97            18.806452                 45.111492  25.567178   \n",
      "\n",
      "    Average_Number_of_Words_Per_Sentence  complex_word_count  \\\n",
      "0                               8.720000                  97   \n",
      "1                              13.200000                 474   \n",
      "2                              14.089286                 444   \n",
      "3                              15.480000                 410   \n",
      "4                              11.717949                 230   \n",
      "..                                   ...                 ...   \n",
      "93                             14.145833                 362   \n",
      "94                             15.447368                 228   \n",
      "95                             24.600000                  59   \n",
      "96                             12.214286                 149   \n",
      "97                             18.806452                 263   \n",
      "\n",
      "    Average_word_length  num_personal_pronouns               URL_ID  \n",
      "0              5.385321                      0  blackassign0001.txt  \n",
      "1              6.097980                      2  blackassign0002.txt  \n",
      "2              6.845374                      1  blackassign0003.txt  \n",
      "3              6.607235                      0  blackassign0004.txt  \n",
      "4              6.356674                      0  blackassign0005.txt  \n",
      "..                  ...                    ...                  ...  \n",
      "93             6.438881                      1  blackassign0096.txt  \n",
      "94             5.381601                      1  blackassign0097.txt  \n",
      "95             5.471545                      0  blackassign0098.txt  \n",
      "96             5.286550                      2  blackassign0099.txt  \n",
      "97             5.981132                      2  blackassign0100.txt  \n",
      "\n",
      "[98 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prondict = cmudict.dict()\n",
    "\n",
    "def count_syllables(word):\n",
    "   \n",
    "    if word.lower() in prondict:\n",
    "      \n",
    "        syllables = [len(list(y for y in x if y[-1].isdigit())) for x in prondict[word.lower()] if not (word.endswith('es') or word.endswith('ed'))]\n",
    "        return max(syllables) if syllables else 0\n",
    "    else:\n",
    "      \n",
    "        return 0\n",
    "\n",
    "def text_analytics(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "   \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "\n",
    "    personal_pronouns = ['I', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "    num_personal_pronouns = sum(1 for word in words if word.lower() in personal_pronouns)\n",
    "\n",
    "   \n",
    "    num_complex_words = sum(1 for word in words if count_syllables(word) > 1)\n",
    "    \n",
    "    percentage_complex_words = (num_complex_words / len(words)) * 100 if words else 0\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    num_sentences = len(sentences)\n",
    "    total_sentence_length = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
    "    avg_sentence_length = total_sentence_length / num_sentences if num_sentences else 0\n",
    "    fog = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    Average_Number_of_Words_Per_Sentence = len(words) / len(sentences)\n",
    "    complex_word_count = sum(1 for word in words if count_syllables(word) > 1)\n",
    "    Average_word_length = sum(len(word) for word in words) / len(words)\n",
    "\n",
    "    return {\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'percentage_complex_words': percentage_complex_words,\n",
    "        'fog': fog,\n",
    "        'Average_Number_of_Words_Per_Sentence': Average_Number_of_Words_Per_Sentence,\n",
    "        'complex_word_count': complex_word_count,\n",
    "        'Average_word_length': Average_word_length,\n",
    "        'num_personal_pronouns': num_personal_pronouns,\n",
    "    }\n",
    "\n",
    "def  process_files_in_directory (article_dir):\n",
    "    file_statistics = []\n",
    "    for filename in os.listdir(article_dir):\n",
    "        file_path = os.path.join(article_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            stats = text_analytics(file_path)\n",
    "            stats['filename'] = filename\n",
    "            file_statistics.append(stats)\n",
    "            print(f\"Processed {filename}: {stats}\")\n",
    "    return file_statistics\n",
    "\n",
    "\n",
    "article_dir = 'articles'\n",
    "\n",
    "\n",
    "file_statistics = process_files_in_directory(article_dir)\n",
    "res_df = pd.DataFrame(file_statistics)\n",
    "res_df['URL_ID'] = res_df['filename']\n",
    "res_df.drop(columns=['filename'], inplace=True)\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d90cd1d5-fb8c-4c2a-a9af-cf01a026a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = results_df.merge(res_df, on='URL_ID', how='inner')\n",
    "merged_df['URL_ID'] = results_df['URL_ID'].str.split('.').str[0]\n",
    "new_df = merged_df.merge(df, on='URL_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a93cd2-d999-4c33-98c3-f65c6f94e752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>Syllable_Count</th>\n",
       "      <th>num_words</th>\n",
       "      <th>Polartiy_Score</th>\n",
       "      <th>Subjectivity_Score</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>fog</th>\n",
       "      <th>Average_Number_of_Words_Per_Sentence</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>Average_word_length</th>\n",
       "      <th>num_personal_pronouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>175</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>8.720000</td>\n",
       "      <td>44.495413</td>\n",
       "      <td>21.286165</td>\n",
       "      <td>8.720000</td>\n",
       "      <td>97</td>\n",
       "      <td>5.385321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>1501</td>\n",
       "      <td>788</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.175983</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>47.878788</td>\n",
       "      <td>24.431515</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>474</td>\n",
       "      <td>6.097980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>1414</td>\n",
       "      <td>637</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>14.089286</td>\n",
       "      <td>56.273764</td>\n",
       "      <td>28.145220</td>\n",
       "      <td>14.089286</td>\n",
       "      <td>444</td>\n",
       "      <td>6.845374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>38</td>\n",
       "      <td>75</td>\n",
       "      <td>1282</td>\n",
       "      <td>617</td>\n",
       "      <td>-0.327434</td>\n",
       "      <td>0.233954</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>52.971576</td>\n",
       "      <td>27.380630</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>410</td>\n",
       "      <td>6.607235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>707</td>\n",
       "      <td>376</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.060041</td>\n",
       "      <td>11.717949</td>\n",
       "      <td>50.328228</td>\n",
       "      <td>24.818471</td>\n",
       "      <td>11.717949</td>\n",
       "      <td>230</td>\n",
       "      <td>6.356674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "\n",
       "   POSITIVE_SCORE  NEGATIVE_SCORE  Syllable_Count  num_words  Polartiy_Score  \\\n",
       "0               6               1             299        175        0.714286   \n",
       "1              56              29            1501        788        0.317647   \n",
       "2              38              24            1414        637        0.225806   \n",
       "3              38              75            1282        617       -0.327434   \n",
       "4              21               8             707        376        0.448276   \n",
       "\n",
       "   Subjectivity_Score  avg_sentence_length  percentage_complex_words  \\\n",
       "0            0.014493             8.720000                 44.495413   \n",
       "1            0.175983            13.200000                 47.878788   \n",
       "2            0.128364            14.089286                 56.273764   \n",
       "3            0.233954            15.480000                 52.971576   \n",
       "4            0.060041            11.717949                 50.328228   \n",
       "\n",
       "         fog  Average_Number_of_Words_Per_Sentence  complex_word_count  \\\n",
       "0  21.286165                              8.720000                  97   \n",
       "1  24.431515                             13.200000                 474   \n",
       "2  28.145220                             14.089286                 444   \n",
       "3  27.380630                             15.480000                 410   \n",
       "4  24.818471                             11.717949                 230   \n",
       "\n",
       "   Average_word_length  num_personal_pronouns  \n",
       "0             5.385321                      0  \n",
       "1             6.097980                      2  \n",
       "2             6.845374                      1  \n",
       "3             6.607235                      0  \n",
       "4             6.356674                      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_order = ['URL_ID', 'URL', 'POSITIVE_SCORE', 'NEGATIVE_SCORE', 'Syllable_Count', 'num_words', 'Polartiy_Score',\n",
    "                 'Subjectivity_Score', 'avg_sentence_length', 'percentage_complex_words', 'fog', \n",
    "                 'Average_Number_of_Words_Per_Sentence', 'complex_word_count', 'Average_word_length', \n",
    "                 'num_personal_pronouns']\n",
    "\n",
    "df = new_df[desired_order]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bff10503-1543-46bd-9e80-5b05d3c212d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output.xlsx'\n",
    "column_mapping = {\n",
    "     'URL':'URL',\n",
    "    'POSITIVE_SCORE': 'POSITIVE SCORE',\n",
    "    'NEGATIVE_SCORE': 'NEGATIVE SCORE',\n",
    "    'Polartiy_Score': 'POLARITY SCORE',\n",
    "    'Subjectivity_Score': 'SUBJECTIVITY SCORE',\n",
    "    'avg_sentence_length': 'AVG SENTENCE LENGTH',\n",
    "    'percentage_complex_words': 'PERCENTAGE OF COMPLEX WORDS',\n",
    "    'fog': 'FOG INDEX',\n",
    "    'Average_Number_of_Words_Per_Sentence': 'AVG NUMBER OF WORDS PER SENTENCE',\n",
    "    'complex_word_countT': 'COMPLEX WORD COUNT',\n",
    "    'num_words': 'WORD COUNT',\n",
    "    'Syllable_Count': 'SYLLABLE PER WORD',\n",
    "    'num_personal_pronouns': 'PERSONAL PRONOUNS',\n",
    "    'Average_word_length': 'AVG WORD LENGTH'\n",
    "}\n",
    "\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    \n",
    "    df.to_excel(writer, sheet_name='Sheet1', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbbdc12-91e6-486d-9ee1-0625dcb06e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
